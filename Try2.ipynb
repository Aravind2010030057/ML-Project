{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a313e863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f5d4801",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cf4833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5013d302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50802ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f07045e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 455 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'dataset/train',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    classes=['class0', 'class1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f14ce191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    'dataset/test',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    classes=['class0', 'class1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db48c58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15/15 [==============================] - 38s 2s/step - loss: 1.0893 - accuracy: 0.5868 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 30s 2s/step - loss: 0.6766 - accuracy: 0.5429 - val_loss: 0.6353 - val_accuracy: 0.6719\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 31s 2s/step - loss: 0.5311 - accuracy: 0.7187 - val_loss: 0.5700 - val_accuracy: 0.6719\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 28s 2s/step - loss: 0.4306 - accuracy: 0.7978 - val_loss: 0.5172 - val_accuracy: 0.7344\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 28s 2s/step - loss: 0.3902 - accuracy: 0.8330 - val_loss: 0.4199 - val_accuracy: 0.8281\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 29s 2s/step - loss: 0.3734 - accuracy: 0.8418 - val_loss: 0.5905 - val_accuracy: 0.6875\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 27s 2s/step - loss: 0.3335 - accuracy: 0.8615 - val_loss: 0.3738 - val_accuracy: 0.8438\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 27s 2s/step - loss: 0.3050 - accuracy: 0.8879 - val_loss: 0.2662 - val_accuracy: 0.8906\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 29s 2s/step - loss: 0.2513 - accuracy: 0.9011 - val_loss: 0.2617 - val_accuracy: 0.8750\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 28s 2s/step - loss: 0.2965 - accuracy: 0.8901 - val_loss: 0.2554 - val_accuracy: 0.9219\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator))\n",
    "\n",
    "# Save the model\n",
    "model.save('glaucoma_detection_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "768fe139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 17s 640ms/step - loss: 0.2554 - accuracy: 0.9219\n",
      "Validation loss: 0.25540608167648315\n",
      "Validation accuracy: 0.921875\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "loaded_model = tf.keras.models.load_model('glaucoma_detection_model.h5')\n",
    "loss, accuracy = loaded_model.evaluate(validation_generator)\n",
    "print('Validation loss:', loss)\n",
    "print('Validation accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1eb79730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6364aa41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 425ms/step\n",
      "Glaucoma\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img('dataset/test/class1/Im263.jpg', target_size = (256,256))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = loaded_model.predict(test_image)\n",
    "#train_generator.class_indices\n",
    "if result == 1:\n",
    " print(\"Glaucoma\")\n",
    "else:\n",
    " print(\"Not Glaucoma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8aad4bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n",
      "Not Glaucoma\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img('Fundus_Scanes_Sorted/Validation/Glaucoma_Positive/621.jpg', target_size = (256,256))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = loaded_model.predict(test_image)\n",
    "#train_generator.class_indices\n",
    "if result[0][0] == 1:\n",
    " print(\"Glaucoma\")\n",
    "else:\n",
    " print(\"Not Glaucoma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be09643",
   "metadata": {},
   "source": [
    "## Using VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1f22cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffe2aaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 455 images belonging to 2 classes.\n",
      "Found 64 images belonging to 2 classes.\n",
      "Epoch 1/30\n",
      "15/15 [==============================] - 157s 10s/step - loss: 1.5590 - accuracy: 0.5516 - val_loss: 0.6774 - val_accuracy: 0.7188\n",
      "Epoch 2/30\n",
      "15/15 [==============================] - 146s 10s/step - loss: 0.6349 - accuracy: 0.6088 - val_loss: 0.6299 - val_accuracy: 0.6719\n",
      "Epoch 3/30\n",
      "15/15 [==============================] - 154s 11s/step - loss: 0.6097 - accuracy: 0.6857 - val_loss: 0.6078 - val_accuracy: 0.7031\n",
      "Epoch 4/30\n",
      "15/15 [==============================] - 165s 11s/step - loss: 0.5873 - accuracy: 0.7165 - val_loss: 0.5930 - val_accuracy: 0.7500\n",
      "Epoch 5/30\n",
      "15/15 [==============================] - 160s 11s/step - loss: 0.5692 - accuracy: 0.6967 - val_loss: 0.5992 - val_accuracy: 0.8125\n",
      "Epoch 6/30\n",
      "15/15 [==============================] - 159s 11s/step - loss: 0.5623 - accuracy: 0.7187 - val_loss: 0.5696 - val_accuracy: 0.7969\n",
      "Epoch 7/30\n",
      "15/15 [==============================] - 170s 11s/step - loss: 0.5406 - accuracy: 0.7429 - val_loss: 0.5586 - val_accuracy: 0.8438\n",
      "Epoch 8/30\n",
      "15/15 [==============================] - 174s 12s/step - loss: 0.5256 - accuracy: 0.7758 - val_loss: 0.5527 - val_accuracy: 0.8438\n",
      "Epoch 9/30\n",
      "15/15 [==============================] - 168s 11s/step - loss: 0.5084 - accuracy: 0.7714 - val_loss: 0.5284 - val_accuracy: 0.8438\n",
      "Epoch 10/30\n",
      "15/15 [==============================] - 174s 12s/step - loss: 0.4936 - accuracy: 0.7956 - val_loss: 0.5160 - val_accuracy: 0.8594\n",
      "Epoch 11/30\n",
      "15/15 [==============================] - 192s 13s/step - loss: 0.4800 - accuracy: 0.8044 - val_loss: 0.5072 - val_accuracy: 0.9062\n",
      "Epoch 12/30\n",
      "15/15 [==============================] - 179s 12s/step - loss: 0.4668 - accuracy: 0.8286 - val_loss: 0.4931 - val_accuracy: 0.8906\n",
      "Epoch 13/30\n",
      "15/15 [==============================] - 172s 11s/step - loss: 0.4558 - accuracy: 0.8132 - val_loss: 0.4869 - val_accuracy: 0.8281\n",
      "Epoch 14/30\n",
      "15/15 [==============================] - 172s 11s/step - loss: 0.4427 - accuracy: 0.8505 - val_loss: 0.4801 - val_accuracy: 0.7969\n",
      "Epoch 15/30\n",
      "15/15 [==============================] - 176s 12s/step - loss: 0.4317 - accuracy: 0.8857 - val_loss: 0.4690 - val_accuracy: 0.8594\n",
      "Epoch 16/30\n",
      "15/15 [==============================] - 174s 12s/step - loss: 0.4298 - accuracy: 0.8703 - val_loss: 0.4624 - val_accuracy: 0.9531\n",
      "Epoch 17/30\n",
      "15/15 [==============================] - 191s 13s/step - loss: 0.4145 - accuracy: 0.8813 - val_loss: 0.4525 - val_accuracy: 0.9375\n",
      "Epoch 18/30\n",
      "15/15 [==============================] - 176s 12s/step - loss: 0.4106 - accuracy: 0.8989 - val_loss: 0.4687 - val_accuracy: 0.9219\n",
      "Epoch 19/30\n",
      "15/15 [==============================] - 164s 11s/step - loss: 0.4013 - accuracy: 0.8791 - val_loss: 0.4413 - val_accuracy: 0.8594\n",
      "Epoch 20/30\n",
      "15/15 [==============================] - 171s 11s/step - loss: 0.4114 - accuracy: 0.8659 - val_loss: 0.4679 - val_accuracy: 0.9219\n",
      "Epoch 21/30\n",
      "15/15 [==============================] - 161s 11s/step - loss: 0.4162 - accuracy: 0.8835 - val_loss: 0.4256 - val_accuracy: 0.9531\n",
      "Epoch 22/30\n",
      "15/15 [==============================] - 157s 11s/step - loss: 0.3867 - accuracy: 0.8989 - val_loss: 0.4169 - val_accuracy: 0.8906\n",
      "Epoch 23/30\n",
      "15/15 [==============================] - 165s 11s/step - loss: 0.3786 - accuracy: 0.8857 - val_loss: 0.4231 - val_accuracy: 0.9531\n",
      "Epoch 24/30\n",
      "15/15 [==============================] - 166s 11s/step - loss: 0.3671 - accuracy: 0.9231 - val_loss: 0.4165 - val_accuracy: 0.9531\n",
      "Epoch 25/30\n",
      "15/15 [==============================] - 185s 12s/step - loss: 0.3701 - accuracy: 0.9099 - val_loss: 0.4405 - val_accuracy: 0.9219\n",
      "Epoch 26/30\n",
      "15/15 [==============================] - 181s 12s/step - loss: 0.3699 - accuracy: 0.8989 - val_loss: 0.3913 - val_accuracy: 0.9062\n",
      "Epoch 27/30\n",
      "15/15 [==============================] - 188s 13s/step - loss: 0.3672 - accuracy: 0.8901 - val_loss: 0.3936 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "15/15 [==============================] - 167s 11s/step - loss: 0.3707 - accuracy: 0.8923 - val_loss: 0.4213 - val_accuracy: 0.9375\n",
      "Epoch 29/30\n",
      "15/15 [==============================] - 163s 11s/step - loss: 0.3530 - accuracy: 0.9297 - val_loss: 0.3965 - val_accuracy: 0.9375\n",
      "Epoch 30/30\n",
      "15/15 [==============================] - 164s 11s/step - loss: 0.3385 - accuracy: 0.9231 - val_loss: 0.3611 - val_accuracy: 0.9531\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# Define the model architecture\n",
    "model = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "model.trainable = False\n",
    "x = keras.layers.Flatten()(model.output)\n",
    "x = keras.layers.Dense(128, activation='relu')(x)\n",
    "predictions = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "model = keras.models.Model(inputs=model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Set up data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'dataset/train',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    classes=['class0', 'class1'])\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    'dataset/test',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    classes=['class0', 'class1'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator))\n",
    "\n",
    "# Save the model\n",
    "model.save('glaucoma_detection_model_vgg16.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d49345ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 21s 10s/step - loss: 0.3611 - accuracy: 0.9531\n",
      "Validation loss: 0.3610827922821045\n",
      "Validation accuracy: 0.953125\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "loss, accuracy = model.evaluate(validation_generator)\n",
    "print('Validation loss:', loss)\n",
    "print('Validation accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81d3398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e954e0c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
